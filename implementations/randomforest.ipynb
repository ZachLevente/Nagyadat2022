{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nagyadat 2022 hf kiindulás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialziation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "import io\n",
    "import requests\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Load the dataset from the github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_train_url = \"https://raw.githubusercontent.com/ZachLevente/Nagyadat2022/main/data/other_train.csv\"\n",
    "prsnl_train_url = \"https://raw.githubusercontent.com/ZachLevente/Nagyadat2022/main/data/personal_train.csv\"\n",
    "other_valid_url = \"https://raw.githubusercontent.com/ZachLevente/Nagyadat2022/main/data/other_valid.csv\"\n",
    "prsnl_valid_url = \"https://raw.githubusercontent.com/ZachLevente/Nagyadat2022/main/data/personal_valid.csv\"\n",
    "\n",
    "db1 = requests.get(other_train_url).content\n",
    "db2 = requests.get(prsnl_train_url).content\n",
    "db3 = requests.get(other_valid_url).content\n",
    "db4 = requests.get(prsnl_valid_url).content\n",
    "\n",
    "personal_train = pd.read_csv(io.StringIO(db1.decode('utf-8')))\n",
    "other_train    = pd.read_csv(io.StringIO(db2.decode('utf-8')))\n",
    "personal_valid = pd.read_csv(io.StringIO(db3.decode('utf-8')))\n",
    "other_valid    = pd.read_csv(io.StringIO(db4.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanitization\n",
    "We have to normalize incoming data, given it's incosistent nature. This can mean missing values from certain entries, diffenet notation for the same concept or simply a too wide value set.\n",
    "In this segment, we define functions that can be later used for transforming data into a consistent, more easily usable form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General value types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_boolean(boolean):\n",
    "    try:\n",
    "        if boolean.strip() in ['f','F','FALSE','false','False']:\n",
    "            return 0\n",
    "        elif boolean.strip() in ['t','T','TRUE','true','True']:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.nan\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "\n",
    "def sanitize_number(number):\n",
    "    try:\n",
    "        sanitized = int(pd.to_numeric(number, errors=\"coerce\"))\n",
    "        return sanitized if sanitized > 0 else np.nan\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def sanitize_string(string):\n",
    "    try:\n",
    "        string = string.strip()\n",
    "        if string in ['None', 'nan', '??', '?']:\n",
    "            return np.nan\n",
    "        return string\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "def sanitize_date(date):\n",
    "    date = str(date).replace('/', '-')\n",
    "    date = date[:10]\n",
    "    date = date.split(\"-\")\n",
    "    \n",
    "    if date[0] != 'nan':\n",
    "        if len(date[0]) != 4:\n",
    "            if len(date[2]) == 2 and int(date[0]) > 31:\n",
    "                new_date = \"19\"+ date[0] +\"-\"+date[1]+\"-\"+date[2] \n",
    "                \n",
    "            elif ((len(date[2]) == 2) and (int(date[0]) < 31) and (int(date[2]) > 31)):\n",
    "                new_date = \"19\"+date[2]+\"-\"+date[1]+\"-\"+date[0] \n",
    "                \n",
    "            elif ((len(date[2]) == 2) and (int(date[0]) < 31) and (int(date[2]) < 31)):\n",
    "                new_date = \"20\"+ date[2] + \"-\" +date[1]+\"-\" + date[0] \n",
    "            else:\n",
    "                new_date = date[2]+\"-\"+date[1]+\"-\"+date[0] \n",
    "            return new_date        \n",
    "    return '-'.join(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project specific types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_sex(sex):\n",
    "    \"\"\"Sex to 1 (male) or 0 (female)\"\"\"\n",
    "    return 1 if sex.strip() == 'Male' else 0\n",
    "\n",
    "def sanitize_pregnancy(data):\n",
    "    \"\"\"Set males to 'not pregnant'\"\"\"\n",
    "    data.loc[(data.sex == 1),'pregnant'] = 0\n",
    "    return data\n",
    "\n",
    "def sanitize_age(data):\n",
    "    \"\"\"Unknown values to np.nan\"\"\"\n",
    "    data.loc[(data.age == '-1'),'age'] = np.nan\n",
    "    data.loc[(data.age == '??'),'age'] = np.nan\n",
    "    return data\n",
    "\n",
    "def sanitize_income(income):\n",
    "    \"\"\"Income to 0 if under 50k, to 1 if over 50k, to np.nan, if unknown\"\"\"\n",
    "    if str(income).strip() == '<=50K':\n",
    "        return 0\n",
    "    elif str(income).strip() == '>50K':\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "def sanitize_relationship(relation):\n",
    "    \"\"\"Narrow value set to 'Married', 'Not-Married', 'Divorced/Widowed'\"\"\"\n",
    "    if relation in ('Married', 'Husband', 'Wife'):\n",
    "        return 'Married'\n",
    "    if relation in ('Not-Married', 'Not-in-family', 'Unmarried', 'Own-child', 'Other-relative'):\n",
    "        return 'Not-Married'\n",
    "    if relation == 'Divorced/Widowed':\n",
    "        return relation\n",
    "    return np.nan\n",
    "\n",
    "def sanitize_marital_status(married):\n",
    "    \"\"\"Narrow value set to 'Married', 'Not-Married', 'Divorced/Widowed'\"\"\"\n",
    "    if married in ('Married', 'Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse'):\n",
    "        return 'Married'\n",
    "    if married in ('Not-Married', 'Never-married'):\n",
    "        return 'Not-Married'\n",
    "    if married in ('Separated', 'Divorced', 'Widowed'):\n",
    "        return 'Divorced/Widowed'\n",
    "    return married\n",
    "\n",
    "def sanitize_work(string):\n",
    "    \"\"\"Change word separator to '_'\"\"\"\n",
    "    try:\n",
    "        return string.replace('-','_').capitalize()\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "# --------------------------------------------------------------------\n",
    "        \n",
    "def fill_null_age(age,date):\n",
    "    if (date):\n",
    "        return (measure_year - int(date.split('-')[0]))[0]\n",
    "    return np.nan\n",
    "    \n",
    "def get_education_num(education, data):\n",
    "    temp = 10.0\n",
    "    for i in data['education-num'].loc[data.education == education]:\n",
    "        if (i > 0) & (i < temp):\n",
    "            temp = i\n",
    "    return temp\n",
    "\n",
    "def clear_nan(data, column):\n",
    "    if data[column].isnull().sum() > 0:\n",
    "            data.dropna(subset=[column], inplace=True)\n",
    "    return data\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "def replace_null_values_with_KNN_imputer(dataframe, no_of_neighbours):\n",
    "    numpy_column = dataframe[['kurtosis_glucose', 'mean_oxygen', 'age']].to_numpy()\n",
    "    numpy_column = np.reshape(numpy_column, (-1,3))\n",
    "\n",
    "    class_column = dataframe['class'].to_numpy()\n",
    "    class_column = np.reshape(numpy_column, (-1,1))\n",
    "\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=no_of_neighbours, weights=\"uniform\")\n",
    "    numpy_column = imputer.fit_transform(numpy_column, class_column)\n",
    "    return numpy_column\n",
    "\n",
    "def replace_null_values_with_KNN_imputer2(dataframe, column, no_of_neighbours):\n",
    "    numpy_column = dataframe[column].to_numpy()\n",
    "    numpy_column = np.reshape(numpy_column, (-1,1))\n",
    "    class_column = dataframe['income'].to_numpy()\n",
    "    class_column = np.reshape(numpy_column, (-1,1))    \n",
    "    imputer = KNNImputer(n_neighbors=no_of_neighbours, weights=\"uniform\")\n",
    "    numpy_column = imputer.fit_transform(numpy_column, class_column)\n",
    "    return numpy_column\n",
    "\n",
    "def replace_with_quantiles(df, column):\n",
    "    new_df = df.copy(deep = True)\n",
    "    skew_val = sc.skew(new_df[column]) \n",
    "    \n",
    "    if ((skew_val < -2) or (skew_val > 2)):  \n",
    "        minimum = new_df[column].min()\n",
    "        minimum = minimum + (-minimum - minimum)\n",
    "        new_df[column] = np.log(new_df[column]+minimum)\n",
    "    \n",
    "    perc_95 = new_df[column].quantile(.95)   \n",
    "    perc_05 =  new_df[column].quantile(.05)\n",
    "    new_df.loc[new_df[column] < perc_05, column] = perc_05\n",
    "    new_df.loc[new_df[column] > perc_95, column] = perc_95\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reparation\n",
    "Using the above defined functions, we can handle all kinds of oddities in the imported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_sanitazition(data):\n",
    "    # Pregnancy\n",
    "    data.pregnant = data.pregnant.map(sanitize_boolean)\n",
    "    data = sanitize_pregnancy(data)\n",
    "    \n",
    "    # Sex\n",
    "    data.sex = data.sex.map(lambda sex: sanitize_sex(sex))\n",
    "    \n",
    "    # Income\n",
    "    data.income = data.income.map(lambda income: sanitize_income(income))    \n",
    "    \n",
    "    # Age\n",
    "    data = sanitize_age(data)\n",
    "    data.age = data.age.map(lambda age: sanitize_number(age))\n",
    "    data.date_of_birth = data.date_of_birth.map(sanitize_date)\n",
    "    \n",
    "    # Split medical info object into separate data columns\n",
    "    split_object = data['medical_info'].str.replace('{','').str.replace('\\'','').str.replace('}', '').str.split(',', expand=True)\n",
    "    i = 0\n",
    "    while i < len(split_object.columns):\n",
    "        info_pair = split_object[i].str.split(':', expand=True)\n",
    "        data[info_pair[0][0]] = info_pair[1].astype(float)\n",
    "        i += 1\n",
    "    data.drop('medical_info', axis='columns', inplace=True)\n",
    "\n",
    "    # Sanitize string values\n",
    "    data['race'] = data['race'].map(sanitize_string)\n",
    "    data.race = data.race.map(lambda race: 'Other' if race in ('Asian-Pac-Islander', 'Amer-Indian-Eskimo') else race)\n",
    "    data['marital-status'] = data['marital-status'].map(sanitize_string)\n",
    "    data['relationship'] = data['relationship'].map(sanitize_string)\n",
    "    data['relationship'] = data['marital-status'].map(sanitize_marital_status)\n",
    "    data['relationship'] = data['relationship'].map(sanitize_relationship)\n",
    "    data.drop('marital-status', axis='columns', inplace=True)\n",
    "    data['occupation'] = data['occupation'].map(sanitize_string)\n",
    "    data['workclass'] = data['workclass'].map(sanitize_string)\n",
    "    data['occupation'] = data['occupation'].map(sanitize_work)\n",
    "    data['workclass'] = data['workclass'].map(sanitize_work)\n",
    "    data['native-country'] = data['native-country'].map(sanitize_string)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def repair_fillinmissing(data):\n",
    "    # calculation of age column values\n",
    "    years = [];\n",
    "    def find_measure_year(age, date_of_birth):\n",
    "        if (pd.notnull(age)):\n",
    "            years.append(int(date_of_birth.split('-')[0]) + int(age))\n",
    "    data.apply(lambda x: find_measure_year(x.age,x.date_of_birth), axis = 1)\n",
    "    measure_year = pd.Series(years).mode();\n",
    "\n",
    "    # Fill in education numbers\n",
    "    map = {}\n",
    "    for i in data.education.unique():\n",
    "        map[i] = (get_education_num(i, data))\n",
    "    data.loc[:,'education-num'] = data.education.map(map)\n",
    "    \n",
    "    # Add hours_per_week\n",
    "    data['hours-per-week'].fillna(round(data['hours-per-week'].mean(), 0), inplace=True)    \n",
    "\n",
    "    # Add income\n",
    "    regression = LinearRegression()\n",
    "    df = data[['hours-per-week','income']]\n",
    "    df2 = data[['hours-per-week','income']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['hours-per-week'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['income'])\n",
    "    data_null = data['hours-per-week'].loc[(data['income'].isna()) & (~data['hours-per-week'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    temp = [np.round(x, 0) for x in temp]\n",
    "    data['income'].loc[(data['income'].isna()) & (~data['hours-per-week'].isna())] = temp\n",
    "\n",
    "    # Add mean_oxygen and kurtosis_glucose\n",
    "    data = clear_nan(data, 'class')\n",
    "    df = data[['kurtosis_glucose', 'mean_oxygen', 'age', 'class']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer(df, 5)\n",
    "    data['kurtosis_glucose'] = numpy_array[:,[0]]\n",
    "    data['mean_oxygen'] = numpy_array[:,[1]]\n",
    "    data['age'] = numpy_array[:,[2]]\n",
    "\n",
    "    # Add mean_glucose\n",
    "    regression = LinearRegression()\n",
    "    df = data[['kurtosis_glucose','mean_glucose']]\n",
    "    df2 = data[['kurtosis_glucose','mean_glucose']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['kurtosis_glucose'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['mean_glucose'])\n",
    "    data_null = data['kurtosis_glucose'].loc[(data['mean_glucose'].isna()) & (~data['kurtosis_glucose'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['mean_glucose'].loc[(data['mean_glucose'].isna()) & (~data['kurtosis_glucose'].isna())] = temp\n",
    "    \n",
    "    # Add kurtosis_oxygen\n",
    "    regression = LinearRegression()\n",
    "    df = data[['mean_oxygen','kurtosis_oxygen']]\n",
    "    df2 = data[['mean_oxygen','kurtosis_oxygen']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['mean_oxygen'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['kurtosis_oxygen'])\n",
    "    data_null = data['mean_oxygen'].loc[(data['kurtosis_oxygen'].isna()) & (~data['mean_oxygen'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['kurtosis_oxygen'].loc[(data['kurtosis_oxygen'].isna()) & (~data['mean_oxygen'].isna())] = temp\n",
    "\n",
    "    # Add skewness_glucose, std_glucose, skewness_oxygen, std_oxygen\n",
    "    regression = LinearRegression()\n",
    "    df = data[['kurtosis_glucose','skewness_glucose']]\n",
    "    df2 = data[['kurtosis_glucose','skewness_glucose']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['kurtosis_glucose'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['skewness_glucose'])\n",
    "    data_null = data['kurtosis_glucose'].loc[(data['skewness_glucose'].isna()) & (~data['kurtosis_glucose'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['skewness_glucose'].loc[(data['skewness_glucose'].isna()) & (~data['kurtosis_glucose'].isna())] = temp\n",
    "    data = clear_nan(data, 'std_glucose')\n",
    "\n",
    "    # Add capital_loss\n",
    "    df = data[['capital-loss', 'income']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer2(df, 'capital-loss', 5)\n",
    "    data['capital-loss'] = numpy_array[:,[0]]\n",
    "    data['capital-loss'] = np.round(data['capital-loss'], 0)\n",
    "    \n",
    "    # Add capital_gain\n",
    "    df = data[['capital-gain', 'income']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer2(df, 'capital-gain', 5)\n",
    "    data['capital-gain'] = numpy_array[:,[0]]\n",
    "    data['capital-gain'] = np.round(data['capital-gain'], 0)\n",
    "\n",
    "    # Add zostavajucich atributov\n",
    "    data.race = data.race.fillna(data.race.mode()[0])\n",
    "    data.pregnant = data.pregnant.fillna(data.pregnant.mode()[0])\n",
    "    data.relationship = data.relationship.fillna(data.relationship.mode()[0])\n",
    "    data.education = data.education.fillna(data.education.mode()[0])\n",
    "    data['occupation'] = data['occupation'].fillna(data.occupation.mode()[0])\n",
    "    data['native-country'] = data['native-country'].fillna(data['native-country'].mode()[0])\n",
    "    data['workclass'] = data['workclass'].fillna(data.workclass.mode()[0])\n",
    "    \n",
    "    return data    \n",
    "    \n",
    "def repair_dropvalues(data):\n",
    "    # Remove erroneous values\n",
    "    median = data[(data.age > 0)].groupby('sex', as_index=False).age.mean()\n",
    "    data.loc[(data.age < 0), 'age'] = data[data.age < 0].age.map(lambda a: round(median.loc[0, 'age'], 0))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    data.drop('Unnamed: 0_x', axis='columns', inplace=True)\n",
    "    data.drop('Unnamed: 0_y', axis='columns', inplace=True)\n",
    "    data.drop('fnlwgt', axis='columns', inplace=True)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    data = data.drop_duplicates(['name','address','date_of_birth'], keep=\"last\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def repair_removeoutliers(data):\n",
    "    data = replace_with_quantiles(data, 'mean_glucose')\n",
    "    data = replace_with_quantiles(data, 'kurtosis_glucose')\n",
    "    data = replace_with_quantiles(data, 'mean_oxygen')\n",
    "    data = replace_with_quantiles(data, 'kurtosis_oxygen')\n",
    "    data = replace_with_quantiles(data, 'skewness_oxygen')\n",
    "    data = replace_with_quantiles(data, 'std_oxygen')\n",
    "    data = replace_with_quantiles(data, 'skewness_glucose')\n",
    "    data = replace_with_quantiles(data, 'std_glucose')\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_data(data):\n",
    "    data = repair_sanitazition(data)\n",
    "    data = repair_dropvalues(data)\n",
    "    data = repair_fillinmissing(data)\n",
    "    data = repair_removeoutliers(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "We merge both the validation and training datasets and run the preprocessing function on them. \n",
    "Preprocessing should be successful in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "train = pd.merge(personal_train,other_train,on=['name','address'], how = 'outer')\n",
    "valid = pd.merge(personal_valid,other_valid,on=['name','address'], how = 'outer')\n",
    "data_train = repair_data(train)\n",
    "data_valid = repair_data(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can get a peek into the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3914 entries, 0 to 3982\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              3914 non-null   object \n",
      " 1   address           3914 non-null   object \n",
      " 2   race              3914 non-null   object \n",
      " 3   occupation        3914 non-null   object \n",
      " 4   pregnant          3914 non-null   float64\n",
      " 5   education-num     3914 non-null   float64\n",
      " 6   relationship      3914 non-null   object \n",
      " 7   capital-gain      3914 non-null   float64\n",
      " 8   education         3914 non-null   object \n",
      " 9   class             3914 non-null   float64\n",
      " 10  income            3914 non-null   float64\n",
      " 11  native-country    3914 non-null   object \n",
      " 12  hours-per-week    3914 non-null   float64\n",
      " 13  capital-loss      3914 non-null   float64\n",
      " 14  workclass         3914 non-null   object \n",
      " 15  age               3914 non-null   float64\n",
      " 16  sex               3914 non-null   int64  \n",
      " 17  date_of_birth     3914 non-null   object \n",
      " 18  mean_glucose      3914 non-null   float64\n",
      " 19  std_glucose       3914 non-null   float64\n",
      " 20  kurtosis_glucose  3914 non-null   float64\n",
      " 21  skewness_glucose  3914 non-null   float64\n",
      " 22  mean_oxygen       3914 non-null   float64\n",
      " 23  std_oxygen        3914 non-null   float64\n",
      " 24  kurtosis_oxygen   3914 non-null   float64\n",
      " 25  skewness_oxygen   3914 non-null   float64\n",
      "dtypes: float64(16), int64(1), object(9)\n",
      "memory usage: 825.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>race</th>\n",
       "      <th>occupation</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>education-num</th>\n",
       "      <th>relationship</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>education</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>mean_glucose</th>\n",
       "      <th>std_glucose</th>\n",
       "      <th>kurtosis_glucose</th>\n",
       "      <th>skewness_glucose</th>\n",
       "      <th>mean_oxygen</th>\n",
       "      <th>std_oxygen</th>\n",
       "      <th>kurtosis_oxygen</th>\n",
       "      <th>skewness_oxygen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason Michaels</td>\n",
       "      <td>498 Kristin Courts Apt. 179\\nWest Teresaport, ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Prof_specialty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1966-05-16</td>\n",
       "      <td>111.812500</td>\n",
       "      <td>44.881746</td>\n",
       "      <td>0.725315</td>\n",
       "      <td>0.690782</td>\n",
       "      <td>0.812044</td>\n",
       "      <td>17.289817</td>\n",
       "      <td>8.636118</td>\n",
       "      <td>4.472571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas Flynn</td>\n",
       "      <td>92949 Wall Drives Apt. 679\\nNew Tinaburgh, MT ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1964-06-29</td>\n",
       "      <td>71.398438</td>\n",
       "      <td>47.295173</td>\n",
       "      <td>1.084843</td>\n",
       "      <td>1.409948</td>\n",
       "      <td>2.827393</td>\n",
       "      <td>46.862830</td>\n",
       "      <td>3.070346</td>\n",
       "      <td>2.432048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Cato</td>\n",
       "      <td>99749 Michael Unions\\nScottstad, IN 48755</td>\n",
       "      <td>White</td>\n",
       "      <td>Prof_specialty</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1954-01-25</td>\n",
       "      <td>102.796875</td>\n",
       "      <td>37.534642</td>\n",
       "      <td>0.704884</td>\n",
       "      <td>1.134939</td>\n",
       "      <td>0.913612</td>\n",
       "      <td>19.874102</td>\n",
       "      <td>7.955210</td>\n",
       "      <td>4.243138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Mcdonald</td>\n",
       "      <td>241 Michael Plains\\nPort Stephanie, OH 65606</td>\n",
       "      <td>White</td>\n",
       "      <td>Adm_clerical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1952-10-30</td>\n",
       "      <td>54.257812</td>\n",
       "      <td>41.582231</td>\n",
       "      <td>1.530575</td>\n",
       "      <td>2.476000</td>\n",
       "      <td>4.680926</td>\n",
       "      <td>64.792196</td>\n",
       "      <td>0.200391</td>\n",
       "      <td>0.727589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel Arreola</td>\n",
       "      <td>4206 Tiffany Land Apt. 402\\nSouth Michael, SC ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1982-01-13</td>\n",
       "      <td>125.492188</td>\n",
       "      <td>56.571304</td>\n",
       "      <td>0.615402</td>\n",
       "      <td>0.309956</td>\n",
       "      <td>1.835787</td>\n",
       "      <td>26.738462</td>\n",
       "      <td>5.595848</td>\n",
       "      <td>3.635864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                            address   race  \\\n",
       "0  Jason Michaels  498 Kristin Courts Apt. 179\\nWest Teresaport, ...  White   \n",
       "1    Thomas Flynn  92949 Wall Drives Apt. 679\\nNew Tinaburgh, MT ...  White   \n",
       "2       John Cato          99749 Michael Unions\\nScottstad, IN 48755  White   \n",
       "3   John Mcdonald       241 Michael Plains\\nPort Stephanie, OH 65606  White   \n",
       "4  Daniel Arreola  4206 Tiffany Land Apt. 402\\nSouth Michael, SC ...  White   \n",
       "\n",
       "       occupation  pregnant  education-num relationship  capital-gain  \\\n",
       "0  Prof_specialty       1.0           10.0      Married           0.0   \n",
       "1           Sales       0.0           10.0      Married           0.0   \n",
       "2  Prof_specialty       0.0           10.0      Married           0.0   \n",
       "3    Adm_clerical       0.0           10.0      Married           0.0   \n",
       "4           Sales       0.0           10.0      Married           0.0   \n",
       "\n",
       "       education  class  ...  sex date_of_birth  mean_glucose  std_glucose  \\\n",
       "0        Masters    0.0  ...    1    1966-05-16    111.812500    44.881746   \n",
       "1   Some-college    1.0  ...    1    1964-06-29     71.398438    47.295173   \n",
       "2        Masters    1.0  ...    1    1954-01-25    102.796875    37.534642   \n",
       "3      Bachelors    1.0  ...    1    1952-10-30     54.257812    41.582231   \n",
       "4   Some-college    0.0  ...    1    1982-01-13    125.492188    56.571304   \n",
       "\n",
       "  kurtosis_glucose  skewness_glucose  mean_oxygen std_oxygen  kurtosis_oxygen  \\\n",
       "0         0.725315          0.690782     0.812044  17.289817         8.636118   \n",
       "1         1.084843          1.409948     2.827393  46.862830         3.070346   \n",
       "2         0.704884          1.134939     0.913612  19.874102         7.955210   \n",
       "3         1.530575          2.476000     4.680926  64.792196         0.200391   \n",
       "4         0.615402          0.309956     1.835787  26.738462         5.595848   \n",
       "\n",
       "   skewness_oxygen  \n",
       "0         4.472571  \n",
       "1         2.432048  \n",
       "2         4.243138  \n",
       "3         0.727589  \n",
       "4         3.635864  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1298 entries, 0 to 1360\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              1298 non-null   object \n",
      " 1   address           1298 non-null   object \n",
      " 2   race              1298 non-null   object \n",
      " 3   occupation        1298 non-null   object \n",
      " 4   pregnant          1298 non-null   float64\n",
      " 5   education-num     1298 non-null   float64\n",
      " 6   relationship      1298 non-null   object \n",
      " 7   capital-gain      1298 non-null   float64\n",
      " 8   education         1298 non-null   object \n",
      " 9   class             1298 non-null   float64\n",
      " 10  income            1298 non-null   float64\n",
      " 11  native-country    1298 non-null   object \n",
      " 12  hours-per-week    1298 non-null   float64\n",
      " 13  capital-loss      1298 non-null   float64\n",
      " 14  workclass         1298 non-null   object \n",
      " 15  age               1298 non-null   float64\n",
      " 16  sex               1298 non-null   int64  \n",
      " 17  date_of_birth     1298 non-null   object \n",
      " 18  mean_glucose      1298 non-null   float64\n",
      " 19  std_glucose       1298 non-null   float64\n",
      " 20  kurtosis_glucose  1298 non-null   float64\n",
      " 21  skewness_glucose  1298 non-null   float64\n",
      " 22  mean_oxygen       1298 non-null   float64\n",
      " 23  std_oxygen        1298 non-null   float64\n",
      " 24  kurtosis_oxygen   1298 non-null   float64\n",
      " 25  skewness_oxygen   1298 non-null   float64\n",
      "dtypes: float64(16), int64(1), object(9)\n",
      "memory usage: 273.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>race</th>\n",
       "      <th>occupation</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>education-num</th>\n",
       "      <th>relationship</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>education</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>mean_glucose</th>\n",
       "      <th>std_glucose</th>\n",
       "      <th>kurtosis_glucose</th>\n",
       "      <th>skewness_glucose</th>\n",
       "      <th>mean_oxygen</th>\n",
       "      <th>std_oxygen</th>\n",
       "      <th>kurtosis_oxygen</th>\n",
       "      <th>skewness_oxygen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steven Sao</td>\n",
       "      <td>83139 Erica Lights Apt. 701\\nEast Billy, IN 37907</td>\n",
       "      <td>White</td>\n",
       "      <td>Machine_op_inspct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Not-Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>109.796875</td>\n",
       "      <td>52.349540</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>0.506528</td>\n",
       "      <td>0.683485</td>\n",
       "      <td>13.008583</td>\n",
       "      <td>10.187234</td>\n",
       "      <td>4.999245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul Le</td>\n",
       "      <td>4644 Sims Pines Suite 561\\nBrandonport, MN 78993</td>\n",
       "      <td>White</td>\n",
       "      <td>Other_service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced/Widowed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1976-07-26</td>\n",
       "      <td>104.070312</td>\n",
       "      <td>39.286047</td>\n",
       "      <td>0.515515</td>\n",
       "      <td>0.986709</td>\n",
       "      <td>1.156808</td>\n",
       "      <td>20.992858</td>\n",
       "      <td>7.445504</td>\n",
       "      <td>4.139537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard Huey</td>\n",
       "      <td>533 Lee Plains\\nPittsberg, NV 72286</td>\n",
       "      <td>White</td>\n",
       "      <td>Craft_repair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1955-03-31</td>\n",
       "      <td>108.453125</td>\n",
       "      <td>45.116665</td>\n",
       "      <td>0.621189</td>\n",
       "      <td>0.933901</td>\n",
       "      <td>1.318406</td>\n",
       "      <td>21.438332</td>\n",
       "      <td>6.699747</td>\n",
       "      <td>3.954960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Wright</td>\n",
       "      <td>PSC 3426, Box 4890\\nAPO AA 62246</td>\n",
       "      <td>White</td>\n",
       "      <td>Exec_managerial</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1976-11-04</td>\n",
       "      <td>122.406250</td>\n",
       "      <td>49.823036</td>\n",
       "      <td>0.312326</td>\n",
       "      <td>0.592041</td>\n",
       "      <td>0.822384</td>\n",
       "      <td>14.796695</td>\n",
       "      <td>8.620707</td>\n",
       "      <td>4.612307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas Grace</td>\n",
       "      <td>3106 Robin Knolls\\nBrookeborough, RI 89626</td>\n",
       "      <td>Black</td>\n",
       "      <td>Prof_specialty</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1944-05-20</td>\n",
       "      <td>54.625000</td>\n",
       "      <td>34.039499</td>\n",
       "      <td>2.202762</td>\n",
       "      <td>2.513813</td>\n",
       "      <td>3.905581</td>\n",
       "      <td>80.697436</td>\n",
       "      <td>1.304086</td>\n",
       "      <td>0.716079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                            address   race  \\\n",
       "0      Steven Sao  83139 Erica Lights Apt. 701\\nEast Billy, IN 37907  White   \n",
       "1         Paul Le   4644 Sims Pines Suite 561\\nBrandonport, MN 78993  White   \n",
       "2    Richard Huey                533 Lee Plains\\nPittsberg, NV 72286  White   \n",
       "3  Michael Wright                   PSC 3426, Box 4890\\nAPO AA 62246  White   \n",
       "4    Thomas Grace         3106 Robin Knolls\\nBrookeborough, RI 89626  Black   \n",
       "\n",
       "          occupation  pregnant  education-num      relationship  capital-gain  \\\n",
       "0  Machine_op_inspct       0.0            9.0       Not-Married           0.0   \n",
       "1      Other_service       1.0            9.0  Divorced/Widowed           0.0   \n",
       "2       Craft_repair       0.0            7.0           Married           0.0   \n",
       "3    Exec_managerial       0.0            9.0           Married           0.0   \n",
       "4     Prof_specialty       0.0           10.0           Married           0.0   \n",
       "\n",
       "    education  class  ...  sex date_of_birth  mean_glucose  std_glucose  \\\n",
       "0     HS-grad    0.0  ...    1    1960-01-02    109.796875    52.349540   \n",
       "1     HS-grad    0.0  ...    0    1976-07-26    104.070312    39.286047   \n",
       "2        11th    0.0  ...    1    1955-03-31    108.453125    45.116665   \n",
       "3     HS-grad    0.0  ...    0    1976-11-04    122.406250    49.823036   \n",
       "4   Bachelors    1.0  ...    1    1944-05-20     54.625000    34.039499   \n",
       "\n",
       "  kurtosis_glucose  skewness_glucose  mean_oxygen std_oxygen  kurtosis_oxygen  \\\n",
       "0         0.366554          0.506528     0.683485  13.008583        10.187234   \n",
       "1         0.515515          0.986709     1.156808  20.992858         7.445504   \n",
       "2         0.621189          0.933901     1.318406  21.438332         6.699747   \n",
       "3         0.312326          0.592041     0.822384  14.796695         8.620707   \n",
       "4         2.202762          2.513813     3.905581  80.697436         1.304086   \n",
       "\n",
       "   skewness_oxygen  \n",
       "0         4.999245  \n",
       "1         4.139537  \n",
       "2         3.954960  \n",
       "3         4.612307  \n",
       "4         0.716079  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing data and creating subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in data_train.columns:\n",
    "    data_train[col] = encoder.fit_transform(data_train[col])\n",
    "for col in data_valid.columns:\n",
    "    data_valid[col] = encoder.fit_transform(data_valid[col])\n",
    "\n",
    "X_train = data_train.drop([\"class\"], axis = 1)\n",
    "Y_train = data_train[\"class\"]\n",
    "X_valid = data_valid.drop([\"class\"], axis = 1)\n",
    "Y_valid = data_valid[\"class\"]\n",
    "\n",
    "alldata=data_train.append(data_valid, ignore_index=True)\n",
    "alldata_X = alldata.drop([\"class\"], axis = 1)\n",
    "alldata_Y = alldata[\"class\"]\n",
    "    \n",
    "X_train_no_glucose = X_train.drop([\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\"], axis = 1)\n",
    "X_valid_no_glucose = X_valid.drop([\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\"], axis = 1)\n",
    "\n",
    "X_train_glucose = data_train[[\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\"]]\n",
    "X_valid_glucose = data_valid[[\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\"]]\n",
    "\n",
    "X_train_no_blood = X_train_no_glucose.drop([\"mean_oxygen\", \"std_oxygen\",\"kurtosis_oxygen\", \"skewness_oxygen\"], axis = 1)\n",
    "X_valid_no_blood = X_valid_no_glucose.drop([\"mean_oxygen\", \"std_oxygen\",\"kurtosis_oxygen\", \"skewness_oxygen\"], axis = 1)\n",
    "\n",
    "X_train_blood = data_train[[\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\", \"mean_oxygen\", \"std_oxygen\",\"kurtosis_oxygen\", \"skewness_oxygen\"]]\n",
    "X_valid_blood = data_valid[[\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\", \"mean_oxygen\", \"std_oxygen\",\"kurtosis_oxygen\", \"skewness_oxygen\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier, parameters were tuned by hand and the most accurate configuration was left in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    random_state=0,\n",
    "    n_estimators=1,\n",
    "    #max_depth=5, \n",
    "    min_samples_split=11,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    min_impurity_decrease=0.0\n",
    "    )\n",
    "\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_valid_pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing training performance results, auc and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[2845   67]\n",
      " [  97  905]]\n",
      "\n",
      "AUC\n",
      "0.940\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      2912\n",
      "           1       0.93      0.90      0.92      1002\n",
      "\n",
      "    accuracy                           0.96      3914\n",
      "   macro avg       0.95      0.94      0.94      3914\n",
      "weighted avg       0.96      0.96      0.96      3914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_train, y_train_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_train, y_train_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_train, y_train_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing validation performance results, auc and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[742 215]\n",
      " [ 22 319]]\n",
      "\n",
      "AUC\n",
      "0.855\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.86       957\n",
      "           1       0.60      0.94      0.73       341\n",
      "\n",
      "    accuracy                           0.82      1298\n",
      "   macro avg       0.78      0.86      0.80      1298\n",
      "weighted avg       0.87      0.82      0.83      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Validation performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_valid, y_valid_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_valid, y_valid_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_valid, y_valid_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the best configuration for subset without glucose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_no_glucose\n",
    "X_valid = X_valid_no_glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    random_state=0,\n",
    "    n_estimators=1,\n",
    "    #max_depth=5, \n",
    "    min_samples_split=11,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    min_impurity_decrease=0.0\n",
    "    )\n",
    "\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_valid_pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[2741  171]\n",
      " [ 219  783]]\n",
      "\n",
      "AUC\n",
      "0.861\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      2912\n",
      "           1       0.82      0.78      0.80      1002\n",
      "\n",
      "    accuracy                           0.90      3914\n",
      "   macro avg       0.87      0.86      0.87      3914\n",
      "weighted avg       0.90      0.90      0.90      3914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_train, y_train_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_train, y_train_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_train, y_train_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[878  79]\n",
      " [303  38]]\n",
      "\n",
      "AUC\n",
      "0.514\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82       957\n",
      "           1       0.32      0.11      0.17       341\n",
      "\n",
      "    accuracy                           0.71      1298\n",
      "   macro avg       0.53      0.51      0.49      1298\n",
      "weighted avg       0.63      0.71      0.65      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Validation performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_valid, y_valid_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_valid, y_valid_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_valid, y_valid_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the best configuration for subset without blood data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_no_blood\n",
    "X_valid = X_valid_no_blood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    random_state=0,\n",
    "    n_estimators=1,\n",
    "    #max_depth=5, \n",
    "    min_samples_split=11,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    min_impurity_decrease=0.0\n",
    "    )\n",
    "\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_valid_pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[2572  340]\n",
      " [ 421  581]]\n",
      "\n",
      "AUC\n",
      "0.732\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      2912\n",
      "           1       0.63      0.58      0.60      1002\n",
      "\n",
      "    accuracy                           0.81      3914\n",
      "   macro avg       0.75      0.73      0.74      3914\n",
      "weighted avg       0.80      0.81      0.80      3914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_train, y_train_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_train, y_train_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_train, y_train_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[756 201]\n",
      " [197 144]]\n",
      "\n",
      "AUC\n",
      "0.606\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       957\n",
      "           1       0.42      0.42      0.42       341\n",
      "\n",
      "    accuracy                           0.69      1298\n",
      "   macro avg       0.61      0.61      0.61      1298\n",
      "weighted avg       0.69      0.69      0.69      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Validation performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_valid, y_valid_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_valid, y_valid_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_valid, y_valid_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the best configuration for subset with only glucose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_glucose\n",
    "X_valid = X_valid_glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    random_state=0,\n",
    "    n_estimators=1,\n",
    "    #max_depth=5, \n",
    "    min_samples_split=11,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    min_impurity_decrease=0.0\n",
    "    )\n",
    "\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_valid_pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[2851   61]\n",
      " [  86  916]]\n",
      "\n",
      "AUC\n",
      "0.947\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      2912\n",
      "           1       0.94      0.91      0.93      1002\n",
      "\n",
      "    accuracy                           0.96      3914\n",
      "   macro avg       0.95      0.95      0.95      3914\n",
      "weighted avg       0.96      0.96      0.96      3914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_train, y_train_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_train, y_train_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_train, y_train_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[957   0]\n",
      " [341   0]]\n",
      "\n",
      "AUC\n",
      "0.500\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       957\n",
      "           1       0.00      0.00      0.00       341\n",
      "\n",
      "    accuracy                           0.74      1298\n",
      "   macro avg       0.37      0.50      0.42      1298\n",
      "weighted avg       0.54      0.74      0.63      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Validation performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_valid, y_valid_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_valid, y_valid_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_valid, y_valid_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the best configuration for subset with only blood data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_blood\n",
    "X_valid = X_valid_blood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    random_state=0,\n",
    "    n_estimators=1,\n",
    "    #max_depth=5, \n",
    "    min_samples_split=11,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    min_impurity_decrease=0.0\n",
    "    )\n",
    "\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_valid_pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[2851   61]\n",
      " [  99  903]]\n",
      "\n",
      "AUC\n",
      "0.940\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      2912\n",
      "           1       0.94      0.90      0.92      1002\n",
      "\n",
      "    accuracy                           0.96      3914\n",
      "   macro avg       0.95      0.94      0.95      3914\n",
      "weighted avg       0.96      0.96      0.96      3914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_train, y_train_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_train, y_train_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_train, y_train_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[956   1]\n",
      " [339   2]]\n",
      "\n",
      "AUC\n",
      "0.502\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       957\n",
      "           1       0.67      0.01      0.01       341\n",
      "\n",
      "    accuracy                           0.74      1298\n",
      "   macro avg       0.70      0.50      0.43      1298\n",
      "weighted avg       0.72      0.74      0.63      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Validation performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_valid, y_valid_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_valid, y_valid_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_valid, y_valid_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "12bdfddc7af913bcc098b9938c8920f353308a887760d668cf2772827525bcf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
