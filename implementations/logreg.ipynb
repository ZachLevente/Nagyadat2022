{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nagyadat 2022 hf kiindulÃ¡s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialziation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "import io\n",
    "import requests\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Load the dataset from the github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_train_url = \"https://raw.githubusercontent.com/ZachLevente/Nagyadat2022/main/data/other_train.csv\"\n",
    "prsnl_train_url = \"https://raw.githubusercontent.com/ZachLevente/Nagyadat2022/main/data/personal_train.csv\"\n",
    "other_valid_url = \"https://raw.githubusercontent.com/ZachLevente/Nagyadat2022/main/data/other_valid.csv\"\n",
    "prsnl_valid_url = \"https://raw.githubusercontent.com/ZachLevente/Nagyadat2022/main/data/personal_valid.csv\"\n",
    "\n",
    "db1 = requests.get(other_train_url).content\n",
    "db2 = requests.get(prsnl_train_url).content\n",
    "db3 = requests.get(other_valid_url).content\n",
    "db4 = requests.get(prsnl_valid_url).content\n",
    "\n",
    "personal_train = pd.read_csv(io.StringIO(db1.decode('utf-8')))\n",
    "other_train    = pd.read_csv(io.StringIO(db2.decode('utf-8')))\n",
    "personal_valid = pd.read_csv(io.StringIO(db3.decode('utf-8')))\n",
    "other_valid    = pd.read_csv(io.StringIO(db4.decode('utf-8')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanitization\n",
    "We have to normalize incoming data, given it's incosistent nature. This can mean missing values from certain entries, diffenet notation for the same concept or simply a too wide value set.\n",
    "In this segment, we define functions that can be later used for transforming data into a consistent, more easily usable form."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General value types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_boolean(boolean):\n",
    "    try:\n",
    "        if boolean.strip() in ['f','F','FALSE','false','False']:\n",
    "            return 0\n",
    "        elif boolean.strip() in ['t','T','TRUE','true','True']:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.nan\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "\n",
    "def sanitize_number(number):\n",
    "    try:\n",
    "        sanitized = int(pd.to_numeric(number, errors=\"coerce\"))\n",
    "        return sanitized if sanitized > 0 else np.nan\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def sanitize_string(string):\n",
    "    try:\n",
    "        string = string.strip()\n",
    "        if string in ['None', 'nan', '??', '?']:\n",
    "            return np.nan\n",
    "        return string\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "def sanitize_date(date):\n",
    "    date = str(date).replace('/', '-')\n",
    "    date = date[:10]\n",
    "    date = date.split(\"-\")\n",
    "    \n",
    "    if date[0] != 'nan':\n",
    "        if len(date[0]) != 4:\n",
    "            if len(date[2]) == 2 and int(date[0]) > 31:\n",
    "                new_date = \"19\"+ date[0] +\"-\"+date[1]+\"-\"+date[2] \n",
    "                \n",
    "            elif ((len(date[2]) == 2) and (int(date[0]) < 31) and (int(date[2]) > 31)):\n",
    "                new_date = \"19\"+date[2]+\"-\"+date[1]+\"-\"+date[0] \n",
    "                \n",
    "            elif ((len(date[2]) == 2) and (int(date[0]) < 31) and (int(date[2]) < 31)):\n",
    "                new_date = \"20\"+ date[2] + \"-\" +date[1]+\"-\" + date[0] \n",
    "            else:\n",
    "                new_date = date[2]+\"-\"+date[1]+\"-\"+date[0] \n",
    "            return new_date        \n",
    "    return '-'.join(date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project specific types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_sex(sex):\n",
    "    \"\"\"Sex to 1 (male) or 0 (female)\"\"\"\n",
    "    return 1 if sex.strip() == 'Male' else 0\n",
    "\n",
    "def sanitize_pregnancy(data):\n",
    "    \"\"\"Set males to 'not pregnant'\"\"\"\n",
    "    data.loc[(data.sex == 1),'pregnant'] = 0\n",
    "    return data\n",
    "\n",
    "def sanitize_age(data):\n",
    "    \"\"\"Unknown values to np.nan\"\"\"\n",
    "    data.loc[(data.age == '-1'),'age'] = np.nan\n",
    "    data.loc[(data.age == '??'),'age'] = np.nan\n",
    "    return data\n",
    "\n",
    "def sanitize_income(income):\n",
    "    \"\"\"Income to 0 if under 50k, to 1 if over 50k, to np.nan, if unknown\"\"\"\n",
    "    if str(income).strip() == '<=50K':\n",
    "        return 0\n",
    "    elif str(income).strip() == '>50K':\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "def sanitize_relationship(relation):\n",
    "    \"\"\"Narrow value set to 'Married', 'Not-Married', 'Divorced/Widowed'\"\"\"\n",
    "    if relation in ('Married', 'Husband', 'Wife'):\n",
    "        return 'Married'\n",
    "    if relation in ('Not-Married', 'Not-in-family', 'Unmarried', 'Own-child', 'Other-relative'):\n",
    "        return 'Not-Married'\n",
    "    if relation == 'Divorced/Widowed':\n",
    "        return relation\n",
    "    return np.nan\n",
    "\n",
    "def sanitize_marital_status(married):\n",
    "    \"\"\"Narrow value set to 'Married', 'Not-Married', 'Divorced/Widowed'\"\"\"\n",
    "    if married in ('Married', 'Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse'):\n",
    "        return 'Married'\n",
    "    if married in ('Not-Married', 'Never-married'):\n",
    "        return 'Not-Married'\n",
    "    if married in ('Separated', 'Divorced', 'Widowed'):\n",
    "        return 'Divorced/Widowed'\n",
    "    return married\n",
    "\n",
    "def sanitize_work(string):\n",
    "    \"\"\"Change word separator to '_'\"\"\"\n",
    "    try:\n",
    "        return string.replace('-','_').capitalize()\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "# --------------------------------------------------------------------\n",
    "        \n",
    "def fill_null_age(age,date):\n",
    "    if (date):\n",
    "        return (measure_year - int(date.split('-')[0]))[0]\n",
    "    return np.nan\n",
    "    \n",
    "def get_education_num(education, data):\n",
    "    temp = 10.0\n",
    "    for i in data['education-num'].loc[data.education == education]:\n",
    "        if (i > 0) & (i < temp):\n",
    "            temp = i\n",
    "    return temp\n",
    "\n",
    "def clear_nan(data, column):\n",
    "    if data[column].isnull().sum() > 0:\n",
    "            data.dropna(subset=[column], inplace=True)\n",
    "    return data\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "def replace_null_values_with_KNN_imputer(dataframe, no_of_neighbours):\n",
    "    numpy_column = dataframe[['kurtosis_glucose', 'mean_oxygen', 'age']].to_numpy()\n",
    "    numpy_column = np.reshape(numpy_column, (-1,3))\n",
    "\n",
    "    class_column = dataframe['class'].to_numpy()\n",
    "    class_column = np.reshape(numpy_column, (-1,1))\n",
    "\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=no_of_neighbours, weights=\"uniform\")\n",
    "    numpy_column = imputer.fit_transform(numpy_column, class_column)\n",
    "    return numpy_column\n",
    "\n",
    "def replace_null_values_with_KNN_imputer2(dataframe, column, no_of_neighbours):\n",
    "    numpy_column = dataframe[column].to_numpy()\n",
    "    numpy_column = np.reshape(numpy_column, (-1,1))\n",
    "    class_column = dataframe['income'].to_numpy()\n",
    "    class_column = np.reshape(numpy_column, (-1,1))    \n",
    "    imputer = KNNImputer(n_neighbors=no_of_neighbours, weights=\"uniform\")\n",
    "    numpy_column = imputer.fit_transform(numpy_column, class_column)\n",
    "    return numpy_column\n",
    "\n",
    "def replace_with_quantiles(df, column):\n",
    "    new_df = df.copy(deep = True)\n",
    "    skew_val = sc.skew(new_df[column]) \n",
    "    \n",
    "    if ((skew_val < -2) or (skew_val > 2)):  \n",
    "        minimum = new_df[column].min()\n",
    "        minimum = minimum + (-minimum - minimum)\n",
    "        new_df[column] = np.log(new_df[column]+minimum)\n",
    "    \n",
    "    perc_95 = new_df[column].quantile(.95)   \n",
    "    perc_05 =  new_df[column].quantile(.05)\n",
    "    new_df.loc[new_df[column] < perc_05, column] = perc_05\n",
    "    new_df.loc[new_df[column] > perc_95, column] = perc_95\n",
    "    return new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reparation\n",
    "Using the above defined functions, we can handle all kinds of oddities in the imported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_sanitazition(data):\n",
    "    # Pregnancy\n",
    "    data.pregnant = data.pregnant.map(sanitize_boolean)\n",
    "    data = sanitize_pregnancy(data)\n",
    "    \n",
    "    # Sex\n",
    "    data.sex = data.sex.map(lambda sex: sanitize_sex(sex))\n",
    "    \n",
    "    # Income\n",
    "    data.income = data.income.map(lambda income: sanitize_income(income))    \n",
    "    \n",
    "    # Age\n",
    "    data = sanitize_age(data)\n",
    "    data.age = data.age.map(lambda age: sanitize_number(age))\n",
    "    data.date_of_birth = data.date_of_birth.map(sanitize_date)\n",
    "    \n",
    "    # Split medical info object into separate data columns\n",
    "    split_object = data['medical_info'].str.replace('{','').str.replace('\\'','').str.replace('}', '').str.split(',', expand=True)\n",
    "    i = 0\n",
    "    while i < len(split_object.columns):\n",
    "        info_pair = split_object[i].str.split(':', expand=True)\n",
    "        data[info_pair[0][0]] = info_pair[1].astype(float)\n",
    "        i += 1\n",
    "    data.drop('medical_info', axis='columns', inplace=True)\n",
    "\n",
    "    # Sanitize string values\n",
    "    data['race'] = data['race'].map(sanitize_string)\n",
    "    data.race = data.race.map(lambda race: 'Other' if race in ('Asian-Pac-Islander', 'Amer-Indian-Eskimo') else race)\n",
    "    data['marital-status'] = data['marital-status'].map(sanitize_string)\n",
    "    data['relationship'] = data['relationship'].map(sanitize_string)\n",
    "    data['relationship'] = data['marital-status'].map(sanitize_marital_status)\n",
    "    data['relationship'] = data['relationship'].map(sanitize_relationship)\n",
    "    data.drop('marital-status', axis='columns', inplace=True)\n",
    "    data['occupation'] = data['occupation'].map(sanitize_string)\n",
    "    data['workclass'] = data['workclass'].map(sanitize_string)\n",
    "    data['occupation'] = data['occupation'].map(sanitize_work)\n",
    "    data['workclass'] = data['workclass'].map(sanitize_work)\n",
    "    data['native-country'] = data['native-country'].map(sanitize_string)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def repair_fillinmissing(data):\n",
    "    # calculation of age column values\n",
    "    years = [];\n",
    "    def find_measure_year(age, date_of_birth):\n",
    "        if (pd.notnull(age)):\n",
    "            years.append(int(date_of_birth.split('-')[0]) + int(age))\n",
    "    data.apply(lambda x: find_measure_year(x.age,x.date_of_birth), axis = 1)\n",
    "    measure_year = pd.Series(years).mode();\n",
    "\n",
    "    # Fill in education numbers\n",
    "    map = {}\n",
    "    for i in data.education.unique():\n",
    "        map[i] = (get_education_num(i, data))\n",
    "    data.loc[:,'education-num'] = data.education.map(map)\n",
    "    \n",
    "    # Add hours_per_week\n",
    "    data['hours-per-week'].fillna(round(data['hours-per-week'].mean(), 0), inplace=True)    \n",
    "\n",
    "    # Add income\n",
    "    regression = LinearRegression()\n",
    "    df = data[['hours-per-week','income']]\n",
    "    df2 = data[['hours-per-week','income']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['hours-per-week'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['income'])\n",
    "    data_null = data['hours-per-week'].loc[(data['income'].isna()) & (~data['hours-per-week'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    temp = [np.round(x, 0) for x in temp]\n",
    "    data['income'].loc[(data['income'].isna()) & (~data['hours-per-week'].isna())] = temp\n",
    "\n",
    "    # Add mean_oxygen and kurtosis_glucose\n",
    "    data = clear_nan(data, 'class')\n",
    "    df = data[['kurtosis_glucose', 'mean_oxygen', 'age', 'class']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer(df, 5)\n",
    "    data['kurtosis_glucose'] = numpy_array[:,[0]]\n",
    "    data['mean_oxygen'] = numpy_array[:,[1]]\n",
    "    data['age'] = numpy_array[:,[2]]\n",
    "\n",
    "    # Add mean_glucose\n",
    "    regression = LinearRegression()\n",
    "    df = data[['kurtosis_glucose','mean_glucose']]\n",
    "    df2 = data[['kurtosis_glucose','mean_glucose']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['kurtosis_glucose'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['mean_glucose'])\n",
    "    data_null = data['kurtosis_glucose'].loc[(data['mean_glucose'].isna()) & (~data['kurtosis_glucose'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['mean_glucose'].loc[(data['mean_glucose'].isna()) & (~data['kurtosis_glucose'].isna())] = temp\n",
    "    \n",
    "    # Add kurtosis_oxygen\n",
    "    regression = LinearRegression()\n",
    "    df = data[['mean_oxygen','kurtosis_oxygen']]\n",
    "    df2 = data[['mean_oxygen','kurtosis_oxygen']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['mean_oxygen'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['kurtosis_oxygen'])\n",
    "    data_null = data['mean_oxygen'].loc[(data['kurtosis_oxygen'].isna()) & (~data['mean_oxygen'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['kurtosis_oxygen'].loc[(data['kurtosis_oxygen'].isna()) & (~data['mean_oxygen'].isna())] = temp\n",
    "\n",
    "    # Add skewness_glucose, std_glucose, skewness_oxygen, std_oxygen\n",
    "    regression = LinearRegression()\n",
    "    df = data[['kurtosis_glucose','skewness_glucose']]\n",
    "    df2 = data[['kurtosis_glucose','skewness_glucose']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['kurtosis_glucose'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['skewness_glucose'])\n",
    "    data_null = data['kurtosis_glucose'].loc[(data['skewness_glucose'].isna()) & (~data['kurtosis_glucose'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['skewness_glucose'].loc[(data['skewness_glucose'].isna()) & (~data['kurtosis_glucose'].isna())] = temp\n",
    "    data = clear_nan(data, 'std_glucose')\n",
    "\n",
    "    # Add capital_loss\n",
    "    df = data[['capital-loss', 'income']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer2(df, 'capital-loss', 5)\n",
    "    data['capital-loss'] = numpy_array[:,[0]]\n",
    "    data['capital-loss'] = np.round(data['capital-loss'], 0)\n",
    "    \n",
    "    # Add capital_gain\n",
    "    df = data[['capital-gain', 'income']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer2(df, 'capital-gain', 5)\n",
    "    data['capital-gain'] = numpy_array[:,[0]]\n",
    "    data['capital-gain'] = np.round(data['capital-gain'], 0)\n",
    "\n",
    "    # Add zostavajucich atributov\n",
    "    data.race = data.race.fillna(data.race.mode()[0])\n",
    "    data.pregnant = data.pregnant.fillna(data.pregnant.mode()[0])\n",
    "    data.relationship = data.relationship.fillna(data.relationship.mode()[0])\n",
    "    data.education = data.education.fillna(data.education.mode()[0])\n",
    "    data['occupation'] = data['occupation'].fillna(data.occupation.mode()[0])\n",
    "    data['native-country'] = data['native-country'].fillna(data['native-country'].mode()[0])\n",
    "    data['workclass'] = data['workclass'].fillna(data.workclass.mode()[0])\n",
    "    \n",
    "    return data    \n",
    "    \n",
    "def repair_dropvalues(data):\n",
    "    # Remove erroneous values\n",
    "    median = data[(data.age > 0)].groupby('sex', as_index=False).age.mean()\n",
    "    data.loc[(data.age < 0), 'age'] = data[data.age < 0].age.map(lambda a: round(median.loc[0, 'age'], 0))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    data.drop('Unnamed: 0_x', axis='columns', inplace=True)\n",
    "    data.drop('Unnamed: 0_y', axis='columns', inplace=True)\n",
    "    data.drop('fnlwgt', axis='columns', inplace=True)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    data = data.drop_duplicates(['name','address','date_of_birth'], keep=\"last\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def repair_removeoutliers(data):\n",
    "    data = replace_with_quantiles(data, 'mean_glucose')\n",
    "    data = replace_with_quantiles(data, 'kurtosis_glucose')\n",
    "    data = replace_with_quantiles(data, 'mean_oxygen')\n",
    "    data = replace_with_quantiles(data, 'kurtosis_oxygen')\n",
    "    data = replace_with_quantiles(data, 'skewness_oxygen')\n",
    "    data = replace_with_quantiles(data, 'std_oxygen')\n",
    "    data = replace_with_quantiles(data, 'skewness_glucose')\n",
    "    data = replace_with_quantiles(data, 'std_glucose')\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_data(data):\n",
    "    data = repair_sanitazition(data)\n",
    "    data = repair_dropvalues(data)\n",
    "    data = repair_fillinmissing(data)\n",
    "    data = repair_removeoutliers(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "We merge both the validation and training datasets and run the preprocessing function on them. \n",
    "Preprocessing should be successful in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "train = pd.merge(personal_train,other_train,on=['name','address'], how = 'outer')\n",
    "valid = pd.merge(personal_valid,other_valid,on=['name','address'], how = 'outer')\n",
    "data_train = repair_data(train)\n",
    "data_valid = repair_data(valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can get a peek into the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3914 entries, 0 to 3982\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              3914 non-null   object \n",
      " 1   address           3914 non-null   object \n",
      " 2   race              3914 non-null   object \n",
      " 3   occupation        3914 non-null   object \n",
      " 4   pregnant          3914 non-null   float64\n",
      " 5   education-num     3914 non-null   float64\n",
      " 6   relationship      3914 non-null   object \n",
      " 7   capital-gain      3914 non-null   float64\n",
      " 8   education         3914 non-null   object \n",
      " 9   class             3914 non-null   float64\n",
      " 10  income            3914 non-null   float64\n",
      " 11  native-country    3914 non-null   object \n",
      " 12  hours-per-week    3914 non-null   float64\n",
      " 13  capital-loss      3914 non-null   float64\n",
      " 14  workclass         3914 non-null   object \n",
      " 15  age               3914 non-null   float64\n",
      " 16  sex               3914 non-null   int64  \n",
      " 17  date_of_birth     3914 non-null   object \n",
      " 18  mean_glucose      3914 non-null   float64\n",
      " 19  std_glucose       3914 non-null   float64\n",
      " 20  kurtosis_glucose  3914 non-null   float64\n",
      " 21  skewness_glucose  3914 non-null   float64\n",
      " 22  mean_oxygen       3914 non-null   float64\n",
      " 23  std_oxygen        3914 non-null   float64\n",
      " 24  kurtosis_oxygen   3914 non-null   float64\n",
      " 25  skewness_oxygen   3914 non-null   float64\n",
      "dtypes: float64(16), int64(1), object(9)\n",
      "memory usage: 825.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>race</th>\n",
       "      <th>occupation</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>education-num</th>\n",
       "      <th>relationship</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>education</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>mean_glucose</th>\n",
       "      <th>std_glucose</th>\n",
       "      <th>kurtosis_glucose</th>\n",
       "      <th>skewness_glucose</th>\n",
       "      <th>mean_oxygen</th>\n",
       "      <th>std_oxygen</th>\n",
       "      <th>kurtosis_oxygen</th>\n",
       "      <th>skewness_oxygen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason Michaels</td>\n",
       "      <td>498 Kristin Courts Apt. 179\\nWest Teresaport, ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Prof_specialty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1966-05-16</td>\n",
       "      <td>111.812500</td>\n",
       "      <td>44.881746</td>\n",
       "      <td>0.725315</td>\n",
       "      <td>0.690782</td>\n",
       "      <td>0.812044</td>\n",
       "      <td>17.289817</td>\n",
       "      <td>8.636118</td>\n",
       "      <td>4.472571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas Flynn</td>\n",
       "      <td>92949 Wall Drives Apt. 679\\nNew Tinaburgh, MT ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1964-06-29</td>\n",
       "      <td>71.398438</td>\n",
       "      <td>47.295173</td>\n",
       "      <td>1.084843</td>\n",
       "      <td>1.409948</td>\n",
       "      <td>2.827393</td>\n",
       "      <td>46.862830</td>\n",
       "      <td>3.070346</td>\n",
       "      <td>2.432048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Cato</td>\n",
       "      <td>99749 Michael Unions\\nScottstad, IN 48755</td>\n",
       "      <td>White</td>\n",
       "      <td>Prof_specialty</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1954-01-25</td>\n",
       "      <td>102.796875</td>\n",
       "      <td>37.534642</td>\n",
       "      <td>0.704884</td>\n",
       "      <td>1.134939</td>\n",
       "      <td>0.913612</td>\n",
       "      <td>19.874102</td>\n",
       "      <td>7.955210</td>\n",
       "      <td>4.243138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Mcdonald</td>\n",
       "      <td>241 Michael Plains\\nPort Stephanie, OH 65606</td>\n",
       "      <td>White</td>\n",
       "      <td>Adm_clerical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1952-10-30</td>\n",
       "      <td>54.257812</td>\n",
       "      <td>41.582231</td>\n",
       "      <td>1.530575</td>\n",
       "      <td>2.476000</td>\n",
       "      <td>4.680926</td>\n",
       "      <td>64.792196</td>\n",
       "      <td>0.200391</td>\n",
       "      <td>0.727589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel Arreola</td>\n",
       "      <td>4206 Tiffany Land Apt. 402\\nSouth Michael, SC ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1982-01-13</td>\n",
       "      <td>125.492188</td>\n",
       "      <td>56.571304</td>\n",
       "      <td>0.615402</td>\n",
       "      <td>0.309956</td>\n",
       "      <td>1.835787</td>\n",
       "      <td>26.738462</td>\n",
       "      <td>5.595848</td>\n",
       "      <td>3.635864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                            address   race  \\\n",
       "0  Jason Michaels  498 Kristin Courts Apt. 179\\nWest Teresaport, ...  White   \n",
       "1    Thomas Flynn  92949 Wall Drives Apt. 679\\nNew Tinaburgh, MT ...  White   \n",
       "2       John Cato          99749 Michael Unions\\nScottstad, IN 48755  White   \n",
       "3   John Mcdonald       241 Michael Plains\\nPort Stephanie, OH 65606  White   \n",
       "4  Daniel Arreola  4206 Tiffany Land Apt. 402\\nSouth Michael, SC ...  White   \n",
       "\n",
       "       occupation  pregnant  education-num relationship  capital-gain  \\\n",
       "0  Prof_specialty       1.0           10.0      Married           0.0   \n",
       "1           Sales       0.0           10.0      Married           0.0   \n",
       "2  Prof_specialty       0.0           10.0      Married           0.0   \n",
       "3    Adm_clerical       0.0           10.0      Married           0.0   \n",
       "4           Sales       0.0           10.0      Married           0.0   \n",
       "\n",
       "       education  class  ...  sex date_of_birth  mean_glucose  std_glucose  \\\n",
       "0        Masters    0.0  ...    1    1966-05-16    111.812500    44.881746   \n",
       "1   Some-college    1.0  ...    1    1964-06-29     71.398438    47.295173   \n",
       "2        Masters    1.0  ...    1    1954-01-25    102.796875    37.534642   \n",
       "3      Bachelors    1.0  ...    1    1952-10-30     54.257812    41.582231   \n",
       "4   Some-college    0.0  ...    1    1982-01-13    125.492188    56.571304   \n",
       "\n",
       "  kurtosis_glucose  skewness_glucose  mean_oxygen std_oxygen  kurtosis_oxygen  \\\n",
       "0         0.725315          0.690782     0.812044  17.289817         8.636118   \n",
       "1         1.084843          1.409948     2.827393  46.862830         3.070346   \n",
       "2         0.704884          1.134939     0.913612  19.874102         7.955210   \n",
       "3         1.530575          2.476000     4.680926  64.792196         0.200391   \n",
       "4         0.615402          0.309956     1.835787  26.738462         5.595848   \n",
       "\n",
       "   skewness_oxygen  \n",
       "0         4.472571  \n",
       "1         2.432048  \n",
       "2         4.243138  \n",
       "3         0.727589  \n",
       "4         3.635864  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1298 entries, 0 to 1360\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              1298 non-null   object \n",
      " 1   address           1298 non-null   object \n",
      " 2   race              1298 non-null   object \n",
      " 3   occupation        1298 non-null   object \n",
      " 4   pregnant          1298 non-null   float64\n",
      " 5   education-num     1298 non-null   float64\n",
      " 6   relationship      1298 non-null   object \n",
      " 7   capital-gain      1298 non-null   float64\n",
      " 8   education         1298 non-null   object \n",
      " 9   class             1298 non-null   float64\n",
      " 10  income            1298 non-null   float64\n",
      " 11  native-country    1298 non-null   object \n",
      " 12  hours-per-week    1298 non-null   float64\n",
      " 13  capital-loss      1298 non-null   float64\n",
      " 14  workclass         1298 non-null   object \n",
      " 15  age               1298 non-null   float64\n",
      " 16  sex               1298 non-null   int64  \n",
      " 17  date_of_birth     1298 non-null   object \n",
      " 18  mean_glucose      1298 non-null   float64\n",
      " 19  std_glucose       1298 non-null   float64\n",
      " 20  kurtosis_glucose  1298 non-null   float64\n",
      " 21  skewness_glucose  1298 non-null   float64\n",
      " 22  mean_oxygen       1298 non-null   float64\n",
      " 23  std_oxygen        1298 non-null   float64\n",
      " 24  kurtosis_oxygen   1298 non-null   float64\n",
      " 25  skewness_oxygen   1298 non-null   float64\n",
      "dtypes: float64(16), int64(1), object(9)\n",
      "memory usage: 273.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>race</th>\n",
       "      <th>occupation</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>education-num</th>\n",
       "      <th>relationship</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>education</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>mean_glucose</th>\n",
       "      <th>std_glucose</th>\n",
       "      <th>kurtosis_glucose</th>\n",
       "      <th>skewness_glucose</th>\n",
       "      <th>mean_oxygen</th>\n",
       "      <th>std_oxygen</th>\n",
       "      <th>kurtosis_oxygen</th>\n",
       "      <th>skewness_oxygen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1143</td>\n",
       "      <td>958</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>560</td>\n",
       "      <td>989</td>\n",
       "      <td>642</td>\n",
       "      <td>259</td>\n",
       "      <td>263</td>\n",
       "      <td>126</td>\n",
       "      <td>888</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>987</td>\n",
       "      <td>458</td>\n",
       "      <td>278</td>\n",
       "      <td>757</td>\n",
       "      <td>734</td>\n",
       "      <td>501</td>\n",
       "      <td>557</td>\n",
       "      <td>591</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>983</td>\n",
       "      <td>642</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>532</td>\n",
       "      <td>541</td>\n",
       "      <td>825</td>\n",
       "      <td>704</td>\n",
       "      <td>576</td>\n",
       "      <td>568</td>\n",
       "      <td>507</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>876</td>\n",
       "      <td>1155</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>994</td>\n",
       "      <td>809</td>\n",
       "      <td>844</td>\n",
       "      <td>594</td>\n",
       "      <td>383</td>\n",
       "      <td>341</td>\n",
       "      <td>252</td>\n",
       "      <td>725</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1169</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>112</td>\n",
       "      <td>104</td>\n",
       "      <td>1012</td>\n",
       "      <td>1050</td>\n",
       "      <td>991</td>\n",
       "      <td>1168</td>\n",
       "      <td>117</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  address  race  occupation  pregnant  education-num  relationship  \\\n",
       "0  1143      958     2           5         0              8             2   \n",
       "1   928      562     2           6         1              8             0   \n",
       "2   983      642     2           1         0              6             1   \n",
       "3   876     1155     2           2         0              8             1   \n",
       "4  1169      380     0           8         0              9             1   \n",
       "\n",
       "   capital-gain  education  class  ...  sex  date_of_birth  mean_glucose  \\\n",
       "0             0         11      0  ...    1            326           560   \n",
       "1             0         11      0  ...    0            987           458   \n",
       "2             0          1      0  ...    1            168           532   \n",
       "3             0         11      0  ...    0            994           809   \n",
       "4             0          9      1  ...    1             31           112   \n",
       "\n",
       "   std_glucose  kurtosis_glucose  skewness_glucose  mean_oxygen  std_oxygen  \\\n",
       "0          989               642               259          263         126   \n",
       "1          278               757               734          501         557   \n",
       "2          541               825               704          576         568   \n",
       "3          844               594               383          341         252   \n",
       "4          104              1012              1050          991        1168   \n",
       "\n",
       "   kurtosis_oxygen  skewness_oxygen  \n",
       "0              888              961  \n",
       "1              591              589  \n",
       "2              507              521  \n",
       "3              725              795  \n",
       "4              117               88  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation - Logistic regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in data_train.columns:\n",
    "    data_train[col] = encoder.fit_transform(data_train[col])\n",
    "for col in data_valid.columns:\n",
    "    data_valid[col] = encoder.fit_transform(data_valid[col])\n",
    "\n",
    "X_train = data_train.drop([\"class\"], axis = 1)\n",
    "Y_train = data_train[\"class\"]\n",
    "X_valid = data_valid.drop([\"class\"], axis = 1)\n",
    "Y_valid = data_valid[\"class\"]\n",
    "\n",
    "alldata=data_train.append(data_valid, ignore_index=True)\n",
    "alldata_X = alldata.drop([\"class\"], axis = 1)\n",
    "alldata_Y = alldata[\"class\"]\n",
    "    \n",
    "X_train_no_glucose = X_train.drop([\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\"], axis = 1)\n",
    "X_valid_no_glucose = X_valid.drop([\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\"], axis = 1)\n",
    "\n",
    "X_glucose = data_train[[\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\"]]\n",
    "X_glucose = data_valid[[\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\"]]\n",
    "\n",
    "X_train_no_blood = X_train_no_glucose.drop([\"mean_oxygen\", \"std_oxygen\",\"kurtosis_oxygen\", \"skewness_oxygen\"], axis = 1)\n",
    "X_valid_no_blood = X_valid_no_glucose.drop([\"mean_oxygen\", \"std_oxygen\",\"kurtosis_oxygen\", \"skewness_oxygen\"], axis = 1)\n",
    "\n",
    "X_train_blood = data_train[[\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\", \"mean_oxygen\", \"std_oxygen\",\"kurtosis_oxygen\", \"skewness_oxygen\"]]\n",
    "X_valid_blood = data_valid[[\"mean_glucose\", \"std_glucose\",\"kurtosis_glucose\", \"skewness_glucose\", \"mean_oxygen\", \"std_oxygen\",\"kurtosis_oxygen\", \"skewness_oxygen\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(\n",
    "    random_state=0,\n",
    "    class_weight='balanced',\n",
    "    max_iter=70,\n",
    "    C=1.2\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = logreg.fit(X_train, Y_train)\n",
    "\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "y_valid_pred = logreg.predict(X_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[2736  176]\n",
      " [  71  931]]\n",
      "\n",
      "AUC\n",
      "0.934\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      2912\n",
      "           1       0.84      0.93      0.88      1002\n",
      "\n",
      "    accuracy                           0.94      3914\n",
      "   macro avg       0.91      0.93      0.92      3914\n",
      "weighted avg       0.94      0.94      0.94      3914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_train, y_train_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_train, y_train_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_train, y_train_pred, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance results:\n",
      "\n",
      "Confusion matrix:\n",
      "[[943  14]\n",
      " [ 43 298]]\n",
      "\n",
      "AUC\n",
      "0.930\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       957\n",
      "           1       0.96      0.87      0.91       341\n",
      "\n",
      "    accuracy                           0.96      1298\n",
      "   macro avg       0.96      0.93      0.94      1298\n",
      "weighted avg       0.96      0.96      0.96      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Validation performance results:')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_valid, y_valid_pred))\n",
    "\n",
    "print('\\nAUC')\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_valid, y_valid_pred)\n",
    "print(f'{metrics.auc(fpr, tpr):.3f}')\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(Y_valid, y_valid_pred, target_names = [\"0\",\"1\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nagyadat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12bdfddc7af913bcc098b9938c8920f353308a887760d668cf2772827525bcf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
